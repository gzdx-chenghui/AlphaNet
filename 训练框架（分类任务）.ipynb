{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d5daaf-c573-49ba-bb92-f916dcba0b95",
   "metadata": {},
   "source": [
    "# 训练框架（分类任务）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36b5a132-bb72-4e4d-bbe3-059e18ec00ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install audtorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d17421-f381-41ca-9a9f-efdd2bc15950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from audtorch.metrics.functional import pearsonr\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, matthews_corrcoef, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46397dc3-b2c5-45e8-b404-e750c876917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU.\n"
     ]
    }
   ],
   "source": [
    "# 设置设备\n",
    "# 因为特征提取层的计算无法完全矩阵化，使用CPU训练更快\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716e60ec-4f91-47ed-b7d5-6d646d5137a1",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "decbdc89-f91d-43a6-a7a8-8a502976c6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (105637, 15, 30)\n",
      "Shape of Y:  (105637,)\n"
     ]
    }
   ],
   "source": [
    "# 导入数据\n",
    "X = np.load('X_fe.npy')\n",
    "Y = np.load('Y_fe_cls.npy')\n",
    "dates = np.load('Y_dates.npy')\n",
    "\n",
    "print('Shape of X: ', X.shape)\n",
    "print('Shape of Y: ', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b9299db-044e-4b0a-bc26-8e782a8a42f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab792a53-3b1e-4311-b6b4-40dae4e4d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    '''\n",
    "    自定义数据集，将原始数据从 numpy arrays 转换成 float 格式的 tensors\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        super(myDataset, self).__init__()\n",
    "        self.X = torch.tensor(X).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a471413-8a03-49a6-b849-b9291de55e03",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7599004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbedc10b-a494-4798-b803-155ba761289a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存模型参数到本地\n",
    "def save_model(model, name):\n",
    "    torch.save(model.state_dict(), name)\n",
    "\n",
    "# 从本地导入模型参数\n",
    "def load_model(model, name):\n",
    "    weights = torch.load(name)\n",
    "    model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edd278c-8494-4ca5-b134-f1bee01ca9b4",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99533150-2523-4a3a-9a4c-116888d39992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.4097],\n",
       "        [ 5.5661],\n",
       "        [ 1.1546],\n",
       "        [ 3.9956],\n",
       "        [ 8.9280]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用小量数据测试模型是否能正常工作\n",
    "net = AlphaNet_v2(d=10, stride=10, n=15)\n",
    "net(torch.tensor(X[:5]).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20256c9-a885-4e62-b07f-a00130072558",
   "metadata": {},
   "source": [
    "## 滚动训练区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d824acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 获取所有标签对应的日期 target_dates 以及数据集中所有不重复的日期 unique_dates\n",
    "target_dates = np.array([datetime.strptime(str(date), '%Y-%m-%d').date() for date in dates])\n",
    "unique_dates = sorted(np.unique(target_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70d2bdd2-8f2e-45fc-a328-8f55b4ba41b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 126, 252, 378, 504, 630]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从2011.01.31开始到2023.05.31，每隔半年滚动训练（测试集为半年126个交易日）\n",
    "# 每次训练数据量为1500个交易日，其中80%是训练集，20%是验证集\n",
    "start_dates = []\n",
    "starts, ends = [], []\n",
    "\n",
    "# 找出所有的训练区间，以便后续划分数据集\n",
    "i, start, end = 0, 0, 0\n",
    "while i + 1200 + 300 + 126 <= len(unique_dates):\n",
    "    start_dates.append(i)\n",
    "    start = sum(target_dates < unique_dates[i])\n",
    "    starts.append(start)\n",
    "    end = sum(target_dates < unique_dates[i+1200+300+126])\n",
    "    ends.append(end)\n",
    "    i += 126\n",
    "\n",
    "# 总共有6个训练区间，模型会在6个数据集上滚动训练\n",
    "start_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b7d10f-8799-47e5-bc7e-75f2eca67e7c",
   "metadata": {},
   "source": [
    "## 验证指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c6d04dd-6403-45ef-8338-02fbce232997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算准确率\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    assert (len(y_true) == len(y_pred))\n",
    "    return accuracy_score(np.array(y_true), np.array(y_pred))\n",
    "\n",
    "# 计算f1-score\n",
    "def compute_f1(y_true, y_pred):\n",
    "    assert (len(y_true) == len(y_pred))\n",
    "    return f1_score(np.array(y_true), np.array(y_pred))\n",
    "\n",
    "# 计算MCC\n",
    "def compute_MCC(y_true, y_pred):\n",
    "    assert (len(y_true) == len(y_pred))\n",
    "    return matthews_corrcoef(np.array(y_true), np.array(y_pred))\n",
    "\n",
    "# 计算4种指标\n",
    "def evaluate_metrics(preds, labels):\n",
    "    labels = [int(item) for item in labels]\n",
    "    preds = [0 if item < 0.5 else 1 for item in preds]\n",
    "    accuracy = compute_accuracy(labels, preds)\n",
    "    f1 = compute_f1(labels, preds)\n",
    "    mcc = compute_MCC(labels, preds)\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    return accuracy, f1, mcc, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0395c864-96a0-43f8-ad71-f24af5af7242",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c3a70c-244d-4d97-94a8-252418a5294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子，保证训练结果一致\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 设置训练参数：学习率、训练迭代次数、批量大小\n",
    "lr = 0.0001\n",
    "n_epoch = 10\n",
    "batch_size = 2000\n",
    "\n",
    "# 初始化训练的对象\n",
    "model_name = 'alphanet_v2_cls'\n",
    "net = AlphaNet_v2(d=10, stride=10, n=15)\n",
    "\n",
    "# 初始化输出处理层（Sigmoid函数）、损失函数和优化器\n",
    "f = nn.Sigmoid()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "# 初始化一个字典，用来储存模型训练期间的表现\n",
    "results = {}\n",
    "results['date'] = []\n",
    "results['train'] = []\n",
    "results['valid'] = []\n",
    "results['test'] = []\n",
    "\n",
    "# 维护 cnt 变量，记录当前是第几个训练轮次\n",
    "cnt = 0\n",
    "\n",
    "# 滚动窗口\n",
    "for start, end in zip(starts, ends):\n",
    "\n",
    "    # 按照 8:4:1 划分出训练、验证和测试集\n",
    "    n = end - start\n",
    "    train_set = myDataset(X[start:start+int(n*8/13)], Y[start:start+int(n*8/13)])\n",
    "    valid_set = myDataset(X[start+int(n*8/13):start+int(n*12/13)], Y[start+int(n*8/13):start+int(n*12/13)])\n",
    "    test_set = myDataset(X[start+int(n*12/13):end], Y[start+int(n*12/13):end])\n",
    "    \n",
    "    # 创建loader\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # 当前训练轮次的模型储存地址\n",
    "    model_path = 'Models/' + model_name + '_' + str(cnt) + '.pt'\n",
    "    \n",
    "    count = 0\n",
    "    train_loss_lst, valid_loss_lst = [], []\n",
    "    best_valid_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        # 训练\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        for x, y in tqdm(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = f(net(x))\n",
    "            loss = criterion(preds, y.unsqueeze(dim=1))\n",
    "            train_loss += loss.item() * len(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss /= len(train_loader.dataset.X)\n",
    "        \n",
    "        \n",
    "        # 验证\n",
    "        net.eval()\n",
    "        valid_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in tqdm(valid_loader):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                preds = f(net(x))\n",
    "                loss = criterion(preds, y.unsqueeze(dim=1))\n",
    "                valid_loss += loss.item() * len(x)\n",
    "        valid_loss /= len(valid_loader.dataset.X)\n",
    "        \n",
    "        \n",
    "        # 监测训练效果\n",
    "        print(\"Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}\".format(epoch+1, train_loss, valid_loss))\n",
    "        \n",
    "        # 记录训练效果\n",
    "        train_loss_lst.append(train_loss)\n",
    "        valid_loss_lst.append(valid_loss)\n",
    "        \n",
    "        # 若当前模型验证效果比历史最佳更好，更新本地模型\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            save_model(net, model_path)\n",
    "            print(\"Saved model with validation loss of {:.4f}\".format(best_valid_loss)) \n",
    "        else:\n",
    "            count += 1\n",
    "            \n",
    "       # 早停：若累计有5次迭代，模型都没有进步，停止本轮训练\n",
    "        if count >= 5:\n",
    "            break\n",
    "\n",
    "    \n",
    "    # 测试最佳模型效果\n",
    "    best_net = AlphaNet_v2(d=10, stride=10, n=15)\n",
    "    load_model(best_net, model_path)\n",
    "    best_net.eval()\n",
    "    test_loss = 0\n",
    "    test_preds, test_labels= [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(test_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = f(best_net(x))\n",
    "            test_preds.append(preds)\n",
    "            test_labels.append(y)\n",
    "            loss = criterion(preds, y.unsqueeze(dim=1))\n",
    "            test_loss += loss.item() * len(x)  \n",
    "    test_loss /= len(test_loader.dataset.X)\n",
    "    test_preds = torch.cat(test_preds)\n",
    "    test_labels = torch.cat(test_labels)\n",
    "    \n",
    "    # 实时监控训练过程中的指标\n",
    "    test_a_i, test_f1_i, test_mcc_i, test_cm_i = evaluate_metrics(test_preds, test_labels)\n",
    "    print(\"\\n\")\n",
    "    print(\"-\" * 50)\n",
    "    print('Test Results: ')\n",
    "    print(\"Accuracy: {:.4f}\".format(test_a_i))\n",
    "    print(\"F1 Score: {:.4f}\".format(test_f1_i))\n",
    "    print(\"MCC Score: {:.4f}\".format(test_mcc_i))\n",
    "    print(\"-\" * 50)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    # 记录当前训练轮次的指标变动，并更新本地储存结果\n",
    "    results['date'].append(str(cnt))       \n",
    "    results['train'].append(train_loss_lst)  \n",
    "    results['valid'].append(valid_loss_lst)  \n",
    "    results['valid'].append([test_a_i, test_f1_i, test_mcc_i, test_cm_i])\n",
    "    with open('train_results_v2_cls.pickle', 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "    \n",
    "    # 下一轮\n",
    "    cnt += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
